{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Description Scenario: ***\n",
        "\n",
        "Sara is a football coach and her team has recently qualified for semi-finals of a most prestigious match of the country. She wants to plan the strategy for the next game based on the video analysis done on the games of the opponent team. Sara has identified three scenarios to be analysed – ‘Goal moments’, ‘Happy moments’, ‘Loss moments’. The analysis would help to learn about the techniques and strategy of the opponent team and hence decide on the strategy for her own team.\n",
        "Requirements: An application to extract the identified scenarios – Goal moments, Happy moments and Loss moments – from the input video. The extracted video segments would be of 30 s to 1 min duration and would be capturing the emotions of the people in the video as well. Extraction should happen in such a way that if “goal” is at “x” min in the video, the extracted segment should start from “x-y” min of the input video and end at “x+y” where “y” is the time in seconds to be considered before and after the shot."
      ],
      "metadata": {
        "id": "QjTeSt5BtIfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROPOSED METHODOLOGY**\n",
        "\n",
        "**1) DATA EXTRACTION**\n",
        "\n",
        "A new datset can be compiled from a public repository like youtube which include‘Goal moments’, ‘Happy moments’and ‘Loss moments’\n",
        "\n",
        "**2) FEATURE EXTRACTION**\n",
        "\n",
        ">> The reasonable selection of models for feature extraction and\n",
        "description plays an important role in the effect of event classification.\n",
        "\n",
        ">>Here, we can employ GoogLeNet(Inception v2 from GoogLeNet as a candidate model for 2D convolutional networks) which achieves better classification results as it uses fewer hierarchical structures and requires a relatively small scale of parameters. \n",
        "\n",
        ">> This convolution method does not take into account the interframe motion in the time dimension, and it is easy to ignore the relevant information between frames.\n",
        "\n",
        ">> When extracting video sequence features, it is possible to save the motion state changes between the frames before and after, thereby improving the accuracy of event classification.Since the convolution kernel weights of each layer are shared throughout the convolution process, only one type of feature can be extracted.\n",
        "\n",
        "**3) EVENT CLASSIFICATION MODEL**\n",
        "\n",
        ">> Event classification model may combine a 3D CNN and a Softmax classifier. The input is an event segment(happy, loss or goal moment), and the sequence features can be extracted from the original frame\n",
        "image through 3D CNN. Further, the probability value can be calculated\n",
        "using the Softmax classifier to get the predicted classification\n",
        "of the event.\n",
        "\n",
        ">> Here, the input is split into two parts: the full-frame image and the\n",
        "central area of the frame. This is because the camera always places the current important moving scene in the center of the camera during the shooting process. Therefore, the probability of occurrence of events in this part is higher, and it is easier to capture the characteristics of events. The central area of the frame is half the size of the full frame.\n",
        "\n",
        ">> Convolutional layers are used to extract features from consecutive frame sequences. Each layer uses a smaller convolution kernel to locally sense the input. In this way, each neuron in a convolutional layer only needs to connect local adjacent regions of the input unit, extracting local information. Global information can then be obtained by integrating\n",
        "at a high level. Compared with the traditional full connection\n",
        "method, more redundant information will not be generated,\n",
        "thereby reducing the complexity of network computing.\n",
        "\n",
        ">> Event detection is the process of locating the time boundary\n",
        "of an event in a complete football video and then classifying\n",
        "it. The event detection model designed is based on the classification model and adds a time series feature integration module. In the model, the video is divided into frame sequences of a specific length, the entire\n",
        "video is scanned by a sliding window, and the starting position of the event is predicted by extracting and integrating the features of multiple frame sequences.\n",
        "\n",
        ">> When only 3D CNN is used, the sequence length that can be processed is limited, and it is easy to ignore the dynamic information contained in\n",
        "the video. Therefore, in the event model, RNN is added to\n",
        "integrate the frame sequence features to further extract the\n",
        "event information contained in the video.\n",
        "\n",
        ">> In the RNN network structure, nodes between hidden\n",
        "layers are fully connected. It adds the output of the hidden\n",
        "layer at the previous time point to the current input to realize\n",
        "the memory of the previous information. In this way, the\n",
        "correlation between the data before and after can be preserved, and the sequence data can be processed more efficiently.There are currently three popular RNN structures: traditional RNN, LSTM, and bidirectional recurrent network BRNN.\n",
        "\n",
        ">> In the video, what happens in the future has a strong correlation with the current state. In this regard, we can use two layers of LSTM to form BLSTM to integrate sequence features, which can simultaneously access past and future contextual information.\n",
        "\n",
        ">> ***TIME BOUNDARY DETECTION ** The time for various events to occur is generally 3 to 4 seconds, and they appear in any time period in the game video. Therefore, in event detection, the video is first divided into a sequence of frames of a certain length. It uses a sliding window to scan the video and multiple frame sequences in a sliding window form a\n",
        "candidate segment, so that after one scan, multiple candidate\n",
        "segments are generated. Each segment is regarded as an independent prediction unit. When multiple prediction results are generated for the same event, the segment with a probability value greater than a certain threshold is selected to enter the postprocessing stage.Through the sliding method,the entire input video can be uniformly processed and the\n",
        "context information of each time point can be preserved.\n",
        "\n",
        ">> After three segments (happy,loss and goal moments) are generated, multiple frame sequences in each segment are input into 3D CNN to extract\n",
        "features. After BLSTM integration, the prediction result of\n",
        "this segment is generated\n",
        "\n",
        "**4) CLASSIFICATION MODEL TRAINING**\n",
        "\n",
        ">> The classification model is fine-tuned on the basis of the existing parameter model. Therefore, in the 3D CNN network, the existing parameter\n",
        "model is used as the initialization parameter, and the learning rate can be given as 0.0001\n",
        "\n",
        ">> A neural network with only convolutional layers is a simple linear regression model, and when the input is complex data types such as images, videos, and audio, it cannot fully learn the intrinsic properties of these data. Therefore, adding an activation function after the convolutional layer can realize the nonlinear function mapping of features to enhance the learning ability of the neural network. There are three choices of activation function: sigmoid function, tanh function, and ReLU function.\n",
        "\n",
        ">> ReLU is a piecewise function, and when the function input is positive, it will keep the size of the value unchanged. When the input is negative, it becomes 0, making a subset of neurons in the neural network inactive to\n",
        "avoid overfitting the training set. Therefore, ReLU can be used here.\n",
        "\n",
        ">> The BLSTM and Softmax classifiers use random initialization\n",
        "parameters, the initial learning rates can be set to 0.001 and 0.01,\n",
        "respectively, and SGD is used to update the parameters. In 3D\n",
        "CNN, the kernel size is 3 × 3 × 3, the stride is 1, the pooling\n",
        "window size is 2 × 2 × 2, the stride is 2, and the dropout rate is\n",
        "0.5. There are 256 hidden units in the hidden layer in BLSTM in the design.\n",
        "When generating the events, the sliding window size is 64 frames and the sliding step size is 16 frames. \n",
        "\n",
        ">> In the training process, it is hoped to obtain a model with relatively small parameters, so that even if the input data has a certain deviation, it will not have a great impact on the results. To a certain extent, the phenomenon of overfitting is avoided\n",
        "\n",
        "**5) FINE-TUNING**\n",
        "\n",
        ">> Fine-tuning the existing parameter model can save a lot of training time. The most important thing in fine-tuning is to select the parameter tuning layer.It can be done employing three schemes. First method is to fix the parameters of all layers unchanged. The second method is to fix all the parameters of the fully connected layer unchanged and fine-tune the parameters of other layers. The third method is to fine-tune the parameters of all layers.\n",
        "\n",
        "-------------------------------------------------------------------------\n",
        "\n",
        "\n",
        ">> Altogether,  The design can be divided into two\n",
        "parts:\n",
        "\n",
        "(1) **classification of football events.** \n",
        "\n",
        "The classification model employs the 3D CNN network and the Softmax classifier for feature extraction and predictive classification for event segments, respectively. According to the characteristics of the football game video, the model input is divided into a full-frame image and a central area of the frame, which are respectively put into 3D CNN to extract features, and feature fusion is performed. The Softmax classifier\n",
        "calculates the predicted value of each category for the event segment and selects the one with the largest predicted value as the predicted category of the event.\n",
        "\n",
        "**(2) Football event detection**\n",
        "\n",
        "The event detection model is based on the classification model by adding the BLSTM structure to better obtain dynamic information between multiple frame sequences. During training, the dataset can be expanded first, and\n",
        "then the event detection model can be optimized using the SGD algorithm. During testing, a sliding window is used to segment the video, input each segment into the model, and calculate the predicted values for all the corresponding categories. Through filtering and merging, the start and end\n",
        "boundaries of events are further confirmed, and category labels can be generated. To verify the validity and correctness of\n",
        "proposed method, comprehensive and systematic experiments can be carried out, and the model can be analyzed from different aspects."
      ],
      "metadata": {
        "id": "-3baTIeRt2fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "O2T2tuzORvW-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_video='/content/sample_data'"
      ],
      "metadata": {
        "id": "y1pbQ4V1Rwom"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}